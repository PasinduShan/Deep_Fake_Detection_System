{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f20b761-69a4-49b1-83ca-6dab8fd4d891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install facenet-pytorch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d397d281-8b50-44cc-b996-1399e30cf06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1840 files belonging to 2 classes.\n",
      "Found 48 files belonging to 2 classes.\n",
      "Found 151 files belonging to 2 classes.\n",
      "Class names: ['fake', 'real']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "# Initialize FaceNet model (pretrained)\n",
    "face_embedding_model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (160, 160)  # Input size required by FaceNet\n",
    "\n",
    "# Load the data from directories\n",
    "train_dir = \"D:/Deep Fake Detection/train\"\n",
    "test_dir = \"D:/Deep Fake Detection/test\"\n",
    "validation_dir = \"D:/Deep Fake Detection/Validation\"\n",
    "\n",
    "# Using TensorFlow's image_dataset_from_directory function to load data\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='binary'  # Assuming binary classification\n",
    ")\n",
    "\n",
    "validation_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='binary'\n",
    ")\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='binary'\n",
    ")\n",
    "\n",
    "# Define class names (based on the folder structure)\n",
    "class_names = train_data.class_names\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# Data Preprocessing (Modify to resize images for FaceNet)\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)  # Resize to 160x160 for FaceNet\n",
    "    image = image / 255.0  # Normalize image\n",
    "    return image, label\n",
    "\n",
    "train_data = train_data.map(preprocess_image)\n",
    "validation_data = validation_data.map(preprocess_image)\n",
    "test_data = test_data.map(preprocess_image)\n",
    "\n",
    "# Function to generate face embeddings\n",
    "def get_face_embedding(image_batch):\n",
    "    # Convert the whole batch from channels-last (TensorFlow) to channels-first (PyTorch)\n",
    "    image_batch = tf.transpose(image_batch, perm=[0, 3, 1, 2])  # [batch_size, channels, height, width]\n",
    "\n",
    "    embeddings = []\n",
    "    for img in image_batch:\n",
    "        img = torch.tensor(img.numpy())  # Convert to PyTorch tensor\n",
    "        img = img.unsqueeze(0)  # img becomes [1, channels, height, width]\n",
    "\n",
    "        embedding = face_embedding_model(img).detach().numpy()  # Get embedding\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcfe5c59-48a4-4fba-9edf-df2afdb12529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face embeddings shape: (32, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "# Test: Get embeddings for a batch of images\n",
    "for image_batch, label_batch in train_data.take(1):\n",
    "    embeddings = get_face_embedding(image_batch)\n",
    "    print(\"Face embeddings shape:\", embeddings.shape)  # Check embedding shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28bdcd02-2481-4d74-94ae-5c637751d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN Model (Modify as needed)\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23113695-1d62-4e0b-b9c2-c81505c4785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add face embeddings layer instead of raw image input\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(512,)))  # FaceNet embedding size is 512\n",
    "\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # Binary classification output\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe913c73-c0a9-4a9b-bd74-1696401d467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop (Embedding extraction included in the loop)\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdb9f3cb-4864-4980-aee5-6288da3c17cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw embedding shape: [ 32   1 512]\n",
      "Squeezed embedding shape: [ 32 512]\n",
      "Label batch shape: [32]\n",
      "Label values: [1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "Epoch 1/20\n",
      "An error occurred during training: Cannot take the length of shape with unknown rank.\n",
      "Total time for training 2.833 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "history = None\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for image_batch, label_batch in train_data.take(1):\n",
    "\n",
    "    image_embeddings = get_face_embedding(image_batch)\n",
    "\n",
    "\n",
    "    print(\"Raw embedding shape:\", tf.shape(image_embeddings).numpy())\n",
    "\n",
    "\n",
    "    image_embeddings = tf.squeeze(image_embeddings)  # Use tf.squeeze instead of np.squeeze\n",
    "\n",
    "\n",
    "    print(\"Squeezed embedding shape:\", tf.shape(image_embeddings).numpy())  # Should be (batch_size, 512)\n",
    "\n",
    "\n",
    "    label_batch = tf.squeeze(label_batch)  # Shape should become (batch_size,)\n",
    "\n",
    "\n",
    "    print(\"Label batch shape:\", tf.shape(label_batch).numpy())  # Should be (batch_size,)\n",
    "    print(\"Label values:\", label_batch.numpy())  # Check the label values to ensure they are 0 and 1 only\n",
    "\n",
    "\n",
    "    try:\n",
    "        history = model.fit(image_embeddings, label_batch, epochs=20, validation_data=validation_data)\n",
    "\n",
    "\n",
    "        if history is None:\n",
    "            print(\"Training did not return any history, something went wrong.\")\n",
    "        else:\n",
    "            print(\"History object returned:\", history.history)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during training: {e}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Total time for training {(end_time-start_time):.3f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae415d3-1e0d-45a8-8d2a-b3c7235fb00b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
